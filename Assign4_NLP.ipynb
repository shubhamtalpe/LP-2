{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "data_path = cwd + \"\\\\Assign4_data\\\\train\"\n",
    "reviews = []\n",
    "for file in os.listdir(data_path):\n",
    "    try:\n",
    "        fd = open(data_path + \"\\\\\" + file)\n",
    "        reviews.append(fd.read())\n",
    "    except:\n",
    "        fd.close()\n",
    "        print(file + \"\\t\" + categ)\n",
    "    else:\n",
    "        fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_reviews = []\n",
    "stemmer = PorterStemmer()\n",
    "for rev in reviews:\n",
    "    review = []\n",
    "    for word in word_tokenize(rev):\n",
    "        if word not in stop_words:\n",
    "            review.append(stemmer.stem(word))\n",
    "    filtered_reviews.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I'm here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn't!\n"
     ]
    }
   ],
   "source": [
    "print(reviews[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bromwel', 'high', 'cartoon', 'comedi', '.', 'It', 'ran', 'time', 'program', 'school', 'life', ',', '``', 'teacher', \"''\", '.', 'My', '35', 'year', 'teach', 'profess', 'lead', 'believ', 'bromwel', 'high', \"'s\", 'satir', 'much', 'closer', 'realiti', '``', 'teacher', \"''\", '.', 'the', 'scrambl', 'surviv', 'financi', ',', 'insight', 'student', 'see', 'right', 'pathet', 'teacher', \"'\", 'pomp', ',', 'petti', 'whole', 'situat', ',', 'remind', 'school', 'I', 'knew', 'student', '.', 'when', 'I', 'saw', 'episod', 'student', 'repeatedli', 'tri', 'burn', 'school', ',', 'I', 'immedi', 'recal', '...', '...', '...', '...', '...', '...', '.', 'high', '.', 'A', 'classic', 'line', ':', 'inspector', ':', 'I', \"'m\", 'sack', 'one', 'teacher', '.', 'student', ':', 'welcom', 'bromwel', 'high', '.', 'I', 'expect', 'mani', 'adult', 'age', 'think', 'bromwel', 'high', 'far', 'fetch', '.', 'what', 'piti', \"n't\", '!']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_reviews[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'story': 227, 'of': 159, 'man': 136, 'who': 278, 'has': 94, 'unnatural': 267, 'feelings': 74, 'for': 78, 'pig': 174, 'starts': 224, 'out': 167, 'with': 280, 'opening': 163, 'scene': 204, 'that': 246, 'is': 113, 'terrific': 243, 'example': 68, 'absurd': 2, 'comedy': 47, 'formal': 79, 'orchestra': 164, 'audience': 17, 'turned': 263, 'into': 112, 'an': 10, 'insane': 107, 'violent': 270, 'mob': 143, 'by': 32, 'the': 247, 'crazy': 49, 'chantings': 40, 'it': 115, 'singers': 215, 'unfortunately': 266, 'stays': 225, 'whole': 279, 'time': 257, 'no': 156, 'general': 86, 'narrative': 150, 'eventually': 66, 'making': 135, 'just': 117, 'too': 259, 'off': 160, 'putting': 184, 'even': 65, 'those': 254, 'from': 83, 'era': 64, 'should': 213, 'be': 19, 'cryptic': 50, 'dialogue': 54, 'would': 282, 'make': 134, 'shakespeare': 212, 'seem': 210, 'easy': 61, 'to': 258, 'third': 252, 'grader': 92, 'on': 161, 'technical': 240, 'level': 128, 'better': 22, 'than': 245, 'you': 285, 'might': 142, 'think': 251, 'some': 221, 'good': 91, 'cinematography': 43, 'future': 85, 'great': 93, 'vilmos': 269, 'zsigmond': 287, 'stars': 223, 'sally': 200, 'kirkland': 119, 'and': 11, 'frederic': 82, 'forrest': 81, 'can': 34, 'seen': 211, 'briefly': 28, 'bromwell': 29, 'high': 99, 'cartoon': 37, 'ran': 185, 'at': 16, 'same': 201, 'as': 15, 'other': 165, 'programs': 183, 'about': 1, 'school': 205, 'life': 129, 'such': 230, 'teachers': 238, 'my': 149, '35': 0, 'years': 284, 'in': 106, 'teaching': 239, 'profession': 182, 'lead': 124, 'me': 141, 'believe': 21, 'satire': 202, 'much': 148, 'closer': 46, 'reality': 187, 'scramble': 207, 'survive': 232, 'financially': 76, 'insightful': 108, 'students': 229, 'see': 209, 'right': 194, 'through': 256, 'their': 248, 'pathetic': 170, 'pomp': 178, 'pettiness': 172, 'situation': 216, 'all': 8, 'remind': 189, 'schools': 206, 'knew': 120, 'when': 276, 'saw': 203, 'episode': 62, 'which': 277, 'student': 228, 'repeatedly': 190, 'tried': 261, 'burn': 30, 'down': 59, 'immediately': 105, 'recalled': 188, 'classic': 44, 'line': 131, 'inspector': 109, 'here': 97, 'sack': 199, 'one': 162, 'your': 286, 'welcome': 274, 'expect': 70, 'many': 138, 'adults': 4, 'age': 7, 'far': 73, 'fetched': 75, 'what': 275, 'pity': 175, 'isn': 114, 'robert': 196, 'deniro': 52, 'plays': 176, 'most': 144, 'unbelievably': 265, 'intelligent': 111, 'illiterate': 103, 'this': 253, 'movie': 146, 'so': 220, 'wasteful': 272, 'talent': 235, 'truly': 262, 'disgusting': 56, 'script': 208, 'unbelievable': 264, 'dialog': 53, 'jane': 116, 'fonda': 77, 'character': 41, 'caricature': 36, 'herself': 98, 'not': 157, 'funny': 84, 'moves': 145, 'snail': 219, 'pace': 168, 'photographed': 173, 'ill': 102, 'advised': 6, 'manner': 137, 'insufferably': 110, 'preachy': 180, 'also': 9, 'plugs': 177, 'every': 67, 'cliche': 45, 'book': 26, 'swoozie': 234, 'kurtz': 122, 'excellent': 69, 'supporting': 231, 'role': 197, 'but': 31, 'br': 27, 'equally': 63, 'annoying': 13, 'new': 154, 'imdb': 104, 'rule': 198, 'requiring': 192, 'ten': 242, 'lines': 132, 'review': 193, 'worthless': 281, 'doesn': 57, 'require': 191, 'text': 244, 'let': 127, 'readers': 186, 'know': 121, 'waste': 271, 'tape': 236, 'avoid': 18, 'if': 101, 'like': 130, 'adult': 3, 'cartoons': 38, 'south': 222, 'park': 169, 'then': 249, 'nearly': 152, 'similar': 214, 'format': 80, 'small': 218, 'adventures': 5, 'three': 255, 'teenage': 241, 'girls': 88, 'keisha': 118, 'natella': 151, 'latrina': 123, 'have': 95, 'given': 89, 'exploding': 71, 'sweets': 233, 'behaved': 20, 'bitches': 24, 'leader': 125, 'there': 250, 'are': 14, 'stories': 226, 'going': 90, 'idiotic': 100, 'principal': 181, 'mr': 147, 'bip': 23, 'nervous': 153, 'maths': 140, 'teacher': 237, 'others': 166, 'cast': 39, 'fantastic': 72, 'lenny': 126, 'henry': 96, 'gina': 87, 'yashere': 283, 'eastenders': 60, 'chrissie': 42, 'watts': 273, 'tracy': 260, 'ann': 12, 'oberman': 158, 'smack': 217, 'pony': 179, 'doon': 58, 'mackichan': 133, 'dead': 51, 'ringers': 195, 'mark': 139, 'perry': 171, 'blunder': 25, 'nina': 155, 'conti': 48, 'didn': 55, 'came': 33, 'canada': 35, 'very': 268}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = cwd + \"\\\\Assign4_data\\\\test\"\n",
    "test = []\n",
    "for file in os.listdir(data_path):\n",
    "    try:\n",
    "        fd = open(data_path + \"\\\\\" + file)\n",
    "        test.append(fd.read())\n",
    "    except:\n",
    "        fd.close()\n",
    "        print(file)\n",
    "    else:\n",
    "        fd.close()\n",
    "newvector = vectorizer.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 1 0\n",
      "  0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      "  0 0 0 0 0 1 0 3 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0\n",
      "  0 0 4 0 0 0 0 0 0 0 0 0 0 2 0 5 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 3 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 7 0 0 0 0\n",
      "  0 3 0 0 0 0 5 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 2 0 0 0 0 2 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(newvector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'story': 227,\n",
       " 'of': 159,\n",
       " 'man': 136,\n",
       " 'who': 278,\n",
       " 'has': 94,\n",
       " 'unnatural': 267,\n",
       " 'feelings': 74,\n",
       " 'for': 78,\n",
       " 'pig': 174,\n",
       " 'starts': 224,\n",
       " 'out': 167,\n",
       " 'with': 280,\n",
       " 'opening': 163,\n",
       " 'scene': 204,\n",
       " 'that': 246,\n",
       " 'is': 113,\n",
       " 'terrific': 243,\n",
       " 'example': 68,\n",
       " 'absurd': 2,\n",
       " 'comedy': 47,\n",
       " 'formal': 79,\n",
       " 'orchestra': 164,\n",
       " 'audience': 17,\n",
       " 'turned': 263,\n",
       " 'into': 112,\n",
       " 'an': 10,\n",
       " 'insane': 107,\n",
       " 'violent': 270,\n",
       " 'mob': 143,\n",
       " 'by': 32,\n",
       " 'the': 247,\n",
       " 'crazy': 49,\n",
       " 'chantings': 40,\n",
       " 'it': 115,\n",
       " 'singers': 215,\n",
       " 'unfortunately': 266,\n",
       " 'stays': 225,\n",
       " 'whole': 279,\n",
       " 'time': 257,\n",
       " 'no': 156,\n",
       " 'general': 86,\n",
       " 'narrative': 150,\n",
       " 'eventually': 66,\n",
       " 'making': 135,\n",
       " 'just': 117,\n",
       " 'too': 259,\n",
       " 'off': 160,\n",
       " 'putting': 184,\n",
       " 'even': 65,\n",
       " 'those': 254,\n",
       " 'from': 83,\n",
       " 'era': 64,\n",
       " 'should': 213,\n",
       " 'be': 19,\n",
       " 'cryptic': 50,\n",
       " 'dialogue': 54,\n",
       " 'would': 282,\n",
       " 'make': 134,\n",
       " 'shakespeare': 212,\n",
       " 'seem': 210,\n",
       " 'easy': 61,\n",
       " 'to': 258,\n",
       " 'third': 252,\n",
       " 'grader': 92,\n",
       " 'on': 161,\n",
       " 'technical': 240,\n",
       " 'level': 128,\n",
       " 'better': 22,\n",
       " 'than': 245,\n",
       " 'you': 285,\n",
       " 'might': 142,\n",
       " 'think': 251,\n",
       " 'some': 221,\n",
       " 'good': 91,\n",
       " 'cinematography': 43,\n",
       " 'future': 85,\n",
       " 'great': 93,\n",
       " 'vilmos': 269,\n",
       " 'zsigmond': 287,\n",
       " 'stars': 223,\n",
       " 'sally': 200,\n",
       " 'kirkland': 119,\n",
       " 'and': 11,\n",
       " 'frederic': 82,\n",
       " 'forrest': 81,\n",
       " 'can': 34,\n",
       " 'seen': 211,\n",
       " 'briefly': 28,\n",
       " 'bromwell': 29,\n",
       " 'high': 99,\n",
       " 'cartoon': 37,\n",
       " 'ran': 185,\n",
       " 'at': 16,\n",
       " 'same': 201,\n",
       " 'as': 15,\n",
       " 'other': 165,\n",
       " 'programs': 183,\n",
       " 'about': 1,\n",
       " 'school': 205,\n",
       " 'life': 129,\n",
       " 'such': 230,\n",
       " 'teachers': 238,\n",
       " 'my': 149,\n",
       " '35': 0,\n",
       " 'years': 284,\n",
       " 'in': 106,\n",
       " 'teaching': 239,\n",
       " 'profession': 182,\n",
       " 'lead': 124,\n",
       " 'me': 141,\n",
       " 'believe': 21,\n",
       " 'satire': 202,\n",
       " 'much': 148,\n",
       " 'closer': 46,\n",
       " 'reality': 187,\n",
       " 'scramble': 207,\n",
       " 'survive': 232,\n",
       " 'financially': 76,\n",
       " 'insightful': 108,\n",
       " 'students': 229,\n",
       " 'see': 209,\n",
       " 'right': 194,\n",
       " 'through': 256,\n",
       " 'their': 248,\n",
       " 'pathetic': 170,\n",
       " 'pomp': 178,\n",
       " 'pettiness': 172,\n",
       " 'situation': 216,\n",
       " 'all': 8,\n",
       " 'remind': 189,\n",
       " 'schools': 206,\n",
       " 'knew': 120,\n",
       " 'when': 276,\n",
       " 'saw': 203,\n",
       " 'episode': 62,\n",
       " 'which': 277,\n",
       " 'student': 228,\n",
       " 'repeatedly': 190,\n",
       " 'tried': 261,\n",
       " 'burn': 30,\n",
       " 'down': 59,\n",
       " 'immediately': 105,\n",
       " 'recalled': 188,\n",
       " 'classic': 44,\n",
       " 'line': 131,\n",
       " 'inspector': 109,\n",
       " 'here': 97,\n",
       " 'sack': 199,\n",
       " 'one': 162,\n",
       " 'your': 286,\n",
       " 'welcome': 274,\n",
       " 'expect': 70,\n",
       " 'many': 138,\n",
       " 'adults': 4,\n",
       " 'age': 7,\n",
       " 'far': 73,\n",
       " 'fetched': 75,\n",
       " 'what': 275,\n",
       " 'pity': 175,\n",
       " 'isn': 114,\n",
       " 'robert': 196,\n",
       " 'deniro': 52,\n",
       " 'plays': 176,\n",
       " 'most': 144,\n",
       " 'unbelievably': 265,\n",
       " 'intelligent': 111,\n",
       " 'illiterate': 103,\n",
       " 'this': 253,\n",
       " 'movie': 146,\n",
       " 'so': 220,\n",
       " 'wasteful': 272,\n",
       " 'talent': 235,\n",
       " 'truly': 262,\n",
       " 'disgusting': 56,\n",
       " 'script': 208,\n",
       " 'unbelievable': 264,\n",
       " 'dialog': 53,\n",
       " 'jane': 116,\n",
       " 'fonda': 77,\n",
       " 'character': 41,\n",
       " 'caricature': 36,\n",
       " 'herself': 98,\n",
       " 'not': 157,\n",
       " 'funny': 84,\n",
       " 'moves': 145,\n",
       " 'snail': 219,\n",
       " 'pace': 168,\n",
       " 'photographed': 173,\n",
       " 'ill': 102,\n",
       " 'advised': 6,\n",
       " 'manner': 137,\n",
       " 'insufferably': 110,\n",
       " 'preachy': 180,\n",
       " 'also': 9,\n",
       " 'plugs': 177,\n",
       " 'every': 67,\n",
       " 'cliche': 45,\n",
       " 'book': 26,\n",
       " 'swoozie': 234,\n",
       " 'kurtz': 122,\n",
       " 'excellent': 69,\n",
       " 'supporting': 231,\n",
       " 'role': 197,\n",
       " 'but': 31,\n",
       " 'br': 27,\n",
       " 'equally': 63,\n",
       " 'annoying': 13,\n",
       " 'new': 154,\n",
       " 'imdb': 104,\n",
       " 'rule': 198,\n",
       " 'requiring': 192,\n",
       " 'ten': 242,\n",
       " 'lines': 132,\n",
       " 'review': 193,\n",
       " 'worthless': 281,\n",
       " 'doesn': 57,\n",
       " 'require': 191,\n",
       " 'text': 244,\n",
       " 'let': 127,\n",
       " 'readers': 186,\n",
       " 'know': 121,\n",
       " 'waste': 271,\n",
       " 'tape': 236,\n",
       " 'avoid': 18,\n",
       " 'if': 101,\n",
       " 'like': 130,\n",
       " 'adult': 3,\n",
       " 'cartoons': 38,\n",
       " 'south': 222,\n",
       " 'park': 169,\n",
       " 'then': 249,\n",
       " 'nearly': 152,\n",
       " 'similar': 214,\n",
       " 'format': 80,\n",
       " 'small': 218,\n",
       " 'adventures': 5,\n",
       " 'three': 255,\n",
       " 'teenage': 241,\n",
       " 'girls': 88,\n",
       " 'keisha': 118,\n",
       " 'natella': 151,\n",
       " 'latrina': 123,\n",
       " 'have': 95,\n",
       " 'given': 89,\n",
       " 'exploding': 71,\n",
       " 'sweets': 233,\n",
       " 'behaved': 20,\n",
       " 'bitches': 24,\n",
       " 'leader': 125,\n",
       " 'there': 250,\n",
       " 'are': 14,\n",
       " 'stories': 226,\n",
       " 'going': 90,\n",
       " 'idiotic': 100,\n",
       " 'principal': 181,\n",
       " 'mr': 147,\n",
       " 'bip': 23,\n",
       " 'nervous': 153,\n",
       " 'maths': 140,\n",
       " 'teacher': 237,\n",
       " 'others': 166,\n",
       " 'cast': 39,\n",
       " 'fantastic': 72,\n",
       " 'lenny': 126,\n",
       " 'henry': 96,\n",
       " 'gina': 87,\n",
       " 'yashere': 283,\n",
       " 'eastenders': 60,\n",
       " 'chrissie': 42,\n",
       " 'watts': 273,\n",
       " 'tracy': 260,\n",
       " 'ann': 12,\n",
       " 'oberman': 158,\n",
       " 'smack': 217,\n",
       " 'pony': 179,\n",
       " 'doon': 58,\n",
       " 'mackichan': 133,\n",
       " 'dead': 51,\n",
       " 'ringers': 195,\n",
       " 'mark': 139,\n",
       " 'perry': 171,\n",
       " 'blunder': 25,\n",
       " 'nina': 155,\n",
       " 'conti': 48,\n",
       " 'didn': 55,\n",
       " 'came': 33,\n",
       " 'canada': 35,\n",
       " 'very': 268}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.91629073, 1.51082562, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.51082562, 1.51082562,\n",
       "       1.51082562, 1.        , 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.22314355, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.51082562,\n",
       "       1.91629073, 1.51082562, 1.91629073, 1.91629073, 1.51082562,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.22314355, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.51082562, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.51082562, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.51082562, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.51082562,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.51082562, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.        , 1.91629073,\n",
       "       1.        , 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.51082562, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.51082562, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.        ,\n",
       "       1.91629073, 1.51082562, 1.51082562, 1.91629073, 1.91629073,\n",
       "       1.51082562, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.51082562, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.51082562, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.51082562, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.51082562, 1.22314355, 1.        , 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.22314355, 1.91629073, 1.51082562, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.22314355, 1.22314355, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.51082562, 1.51082562, 1.91629073, 1.51082562, 1.51082562,\n",
       "       1.51082562, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.51082562, 1.91629073, 1.91629073])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "newvector = vectorizer.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.20109192\n",
      "  0.         0.         0.         0.09633765 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07595371 0.19267529 0.         0.07595371 0.\n",
      "  0.         0.         0.         0.         0.         0.09633765\n",
      "  0.         0.         0.         0.         0.         0.06149107\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.07595371\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07595371 0.         0.09633765 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.07595371 0.\n",
      "  0.         0.         0.         0.         0.         0.05027298\n",
      "  0.         0.15081894 0.         0.         0.         0.\n",
      "  0.09633765 0.         0.         0.         0.         0.\n",
      "  0.         0.09633765 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15190741 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.38535058 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.19267529 0.         0.2513649  0.         0.\n",
      "  0.07595371 0.         0.         0.         0.         0.09633765\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.19267529\n",
      "  0.         0.         0.         0.         0.         0.28901294\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.09633765 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.24596429 0.35191086 0.         0.         0.         0.\n",
      "  0.         0.22786112 0.         0.         0.         0.\n",
      "  0.30745536 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.09633765 0.\n",
      "  0.         0.         0.         0.         0.         0.07595371\n",
      "  0.         0.09633765 0.         0.         0.15190741 0.\n",
      "  0.         0.         0.         0.15190741 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(newvector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
